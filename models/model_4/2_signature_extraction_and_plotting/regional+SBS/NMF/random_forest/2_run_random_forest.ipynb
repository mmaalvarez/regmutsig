{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99131f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Modelling\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Tree Visualisation\n",
    "from sklearn.tree import export_graphviz\n",
    "from IPython.display import Image\n",
    "import graphviz\n",
    "\n",
    "# arguments\n",
    "import sys\n",
    "import argparse\n",
    "import os\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535dcf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "## parse arguments\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('-i', '--input_dir_path', type=str)\n",
    "parser.add_argument('-p', '--NMF_parameters', type=str, help='nFact and k values')\n",
    "parser.add_argument('-g', '--alteration', type=str, help='Alteration for which we want to predict whether a sample is altered or WT')\n",
    "parser.add_argument('-s', '--seed', type=int, help='Seed for all functions that involve some randomness: train_test_split, RandomForestClassifier, RandomizedSearchCV')\n",
    "\n",
    "# if interactive, pass some values manually\n",
    "if 'ipykernel' in sys.modules:\n",
    "    args = parser.parse_args(['-i', '/home/jovyan/fsupek_data/users/malvarez/projects/RepDefSig/models/model_2/2_signature_extraction_and_plotting/regional+SBS/NMF/random_forest/rf_inputs', \n",
    "                              '-p', 'nFact-11_k-11', \n",
    "                              '-g', 'Nitrosamines', \n",
    "                              '-s', '0'])\n",
    "else:\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "input_dir_path, NMF_parameters, alteration, seed = args.input_dir_path, args.NMF_parameters, args.alteration, args.seed\n",
    "\n",
    "test_size = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaeda071",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92f549b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict single prediction_scope\n",
    "for f in glob(f'{input_dir_path}/res_{NMF_parameters}/*/{alteration}_exposures.tsv'):\n",
    "    prediction_scope = f.split('/')[-2]\n",
    "    exposures = pd.read_csv(f, sep=\"\\t\")\n",
    "\n",
    "signature_names = exposures.drop(['id','altered_sample'], axis=1).keys().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4554db03",
   "metadata": {},
   "source": [
    "Downsample the normal samples (i.e. with a '0') to match the number of case samples ('1's)\n",
    "\n",
    "Since I do `sample(frac=0.99-fraction_cases)` there should be slightly more 0's than 1's, still"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95202146",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_samples = exposures.shape[0]\n",
    "number_cases = exposures[exposures['altered_sample']==1].shape[0]\n",
    "fraction_cases = number_cases/number_samples\n",
    "exposures_normal_cases_matched = exposures.drop(exposures[exposures['altered_sample'] == 0].sample(frac=0.99-fraction_cases).index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d3ea6a",
   "metadata": {},
   "source": [
    "Split data into features (X) and target (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3444b0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = exposures_normal_cases_matched.drop(['id','altered_sample'], axis=1)\n",
    "y = exposures_normal_cases_matched['altered_sample']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8916015a",
   "metadata": {},
   "source": [
    "Split both X and y into training and test data\n",
    "- Training data is used to fit the model. The algorithm uses the training data to learn the relationship between the features and the target\n",
    "- Test data is used to evaluate the performance of the model\n",
    "  - test_size indicates the fraction of the original data to be used as test (its complement will be the fraction used as training data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c91f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3c5320",
   "metadata": {
    "tags": []
   },
   "source": [
    "Hyperparameter Tuning\n",
    "---------------------\n",
    "\n",
    "RandomizedSearchCV randomly search parameters within a range per hyperparameter. We define the hyperparameters to use and their ranges in the param_dist dictionary. In our case, we are using:\n",
    "\n",
    "- n_estimators: the number of decision trees in the forest. Increasing this hyperparameter prediction_scoperally improves the performance of the model but also increases the computational cost of training and predicting.\n",
    "- max_depth: the maximum depth of each decision tree in the forest. Setting a higher value for max_depth can lead to overfitting while setting it too low can lead to underfitting\n",
    "- random_state is a seed for reproducing results\n",
    "\n",
    "RandomizedSearchCV will train many models (defined by n_iter_ and save each one as variables, the code below creates a variable for the best model and prints the hyperparameters. In this case, we haven’t passed a scoring system to the function, so it defaults to accuracy. This function also uses cross validation, which means it splits the data into five equal-sized groups and uses 4 to train and 1 to test the result. It will loop through each group and give an accuracy score, which is averaged to find the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d763b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {'n_estimators': randint(50,500),\n",
    "              'max_depth': randint(1,20)}\n",
    "\n",
    "## Create an instance of the Random Forest model, with the default parameters\n",
    "rf = RandomForestClassifier(random_state=seed,\n",
    "                            oob_score=True)\n",
    "\n",
    "## Use random search to find the best hyperparameters\n",
    "rand_search = RandomizedSearchCV(rf, \n",
    "                                 param_distributions = param_dist, \n",
    "                                 n_iter=5, \n",
    "                                 cv=5,\n",
    "                                 random_state=seed)\n",
    "\n",
    "## Fit the random search object to our training data. We pass both the features and the target variable, so the model can learn.\n",
    "rand_search.fit(X_train, y_train)\n",
    "\n",
    "## Create a variable for the best model\n",
    "best_rf = rand_search.best_estimator_\n",
    "\n",
    "## Print the best hyperparameters\n",
    "#print('Best hyperparameters:', rand_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa71471",
   "metadata": {},
   "source": [
    "At this point, we have a trained Random Forest model, but we need to find out whether it is making accurate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71177e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "## rate predictions with the best model\n",
    "y_pred = best_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ffa9e5",
   "metadata": {},
   "source": [
    "Evaluate this model using *out-of-bag* score; also can do accuracy, precision, and recall; we check the predictions against the actual values in the test set and count up how many the model got right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a0816c",
   "metadata": {},
   "outputs": [],
   "source": [
    "oob = best_rf.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f4f552",
   "metadata": {},
   "source": [
    "The confusion matrix plots what the model predicted against what the correct prediction was. We can use this to understand the tradeoff between false positives (top right) and false negatives(bottom left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e413a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the confusion matrix\n",
    "#cm = confusion_matrix(y_test, y_test)\n",
    "\n",
    "# plot it\n",
    "#ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=True).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b41bb5",
   "metadata": {},
   "source": [
    "Plot the importance of each feature, using the model’s internal score to find the best way to split the data within each decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99bc759",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a series containing feature importances from the model and feature names from the training data\n",
    "feature_importances = pd.Series(best_rf.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
    "\n",
    "#feature_importances.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c151ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "## print output table\n",
    "res = pd.DataFrame({'NMF_parameters': [NMF_parameters],\n",
    "                    'test_size': [test_size],\n",
    "                    'prediction_scope': [prediction_scope],\n",
    "                    'alteration': [alteration],\n",
    "                    'seed': [seed],\n",
    "                    'oob': [oob],\n",
    "                    'n_cases': [number_cases]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf66722",
   "metadata": {},
   "outputs": [],
   "source": [
    "## write results table\n",
    "\n",
    "#list(res.columns)\n",
    "\n",
    "res.to_csv(f'res_{NMF_parameters}_{prediction_scope}_{alteration}_{seed}.csv', header=True, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fba15c4",
   "metadata": {},
   "source": [
    "Visualize the first 3 trees\n",
    "---------------------------\n",
    "\n",
    "Each tree image is limited to only showing the first few nodes. These trees can get very large and difficult to visualize. The colors represent the majority class of each node (boxes). The colors get darker the closer the node gets to being fully a category. Each node also contains the following information:\n",
    "\n",
    "1- The variable name and value used for splitting\n",
    "\n",
    "2- The % of total samples in each split\n",
    "\n",
    "3- The % split between classes in each split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87da6990",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for i in range(3):\n",
    "    tree = best_rf.estimators_[i]\n",
    "    dot_data = export_graphviz(tree,\n",
    "                               feature_names=X_train.columns,  \n",
    "                               filled=True,  \n",
    "                               max_depth=2, \n",
    "                               impurity=False, \n",
    "                               proportion=True)\n",
    "    graph = graphviz.Source(dot_data)\n",
    "    display(graph)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
