{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b2aa7614",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load modules and functions\n",
    "\n",
    "# Data Processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Modelling\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Tree Visualisation\n",
    "from sklearn.tree import export_graphviz\n",
    "from IPython.display import Image\n",
    "import graphviz\n",
    "\n",
    "# arguments\n",
    "import sys\n",
    "import argparse\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "933f3b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## parse arguments\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('-i', '--input_dir_path', type=str, help='Full path of the input directory')\n",
    "parser.add_argument('-p', '--autoencoder_parameters', type=str, help='String containing specific parameters used in the autoencoder')\n",
    "parser.add_argument('-f', '--feature', type=str, help='Which simulated feature==\\'high\\' genomic regions have been hypermutated (Phenotype==1), or not (Phenotype==0)')\n",
    "parser.add_argument('-t', '--test_size', type=float, help='Fraction of the original data to be used as test (its complement will be the fraction used as training data)')\n",
    "parser.add_argument('-s', '--seed', type=int, help='Seed for all functions that involve some randomness: train_test_split, RandomForestClassifier, RandomizedSearchCV')\n",
    "\n",
    "# if interactive, pass some values manually\n",
    "if 'ipykernel' in sys.modules:\n",
    "    args = parser.parse_args(['-i',\"/home/jovyan/franklin/malvarez/rf_inputs\",\n",
    "                              '-p',\"8_1_1_100_200_relu_glorot.uniform_mean.squared.error_0.0001_Adam\",\n",
    "                              '-f','feature1', \n",
    "                              '-t','0.2', \n",
    "                              '-s','0'])\n",
    "else:\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "input_dir_path,autoencoder_parameters,feature,test_size,seed = args.input_dir_path,args.autoencoder_parameters,args.feature,args.test_size,args.seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fecc379e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load and parse data\n",
    "\n",
    "exposures = pd.read_csv(f'{input_dir_path}/{autoencoder_parameters}/{feature}_exposures.tsv', sep=\"\\t\")\n",
    "\n",
    "# Training data is used to fit the model. The algorithm uses the training data to learn the relationship between the features and the target: USING TRAINING SAMPLES FROM AE\n",
    "ae_training_samples = exposures[exposures['train_val'] == \"training\"].drop('train_val', axis=1)\n",
    "# Test data is used to evaluate the performance of the model: USING VALIDATION SAMPLES FROM AE\n",
    "ae_validation_samples = exposures[exposures['train_val'] == \"validation\"].drop('train_val', axis=1)\n",
    "\n",
    "## Split both training and testing data into features (X, the exposures, the predictor) and target (y, the Phenotype column, that we want to predict)\n",
    "X_train = ae_training_samples.drop('Phenotype', axis=1)\n",
    "y_train = ae_training_samples['Phenotype']\n",
    "X_test = ae_validation_samples.drop('Phenotype', axis=1)\n",
    "y_test = ae_validation_samples['Phenotype']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7670d42e",
   "metadata": {
    "tags": []
   },
   "source": [
    "Hyperparameter Tuning\n",
    "---------------------\n",
    "\n",
    "RandomizedSearchCV randomly search parameters within a range per hyperparameter. We define the hyperparameters to use and their ranges in the param_dist dictionary. In our case, we are using:\n",
    "\n",
    "- n_estimators: the number of decision trees in the forest. Increasing this hyperparameter generally improves the performance of the model but also increases the computational cost of training and predicting.\n",
    "- max_depth: the maximum depth of each decision tree in the forest. Setting a higher value for max_depth can lead to overfitting while setting it too low can lead to underfitting\n",
    "- random_state is a seed for reproducing results\n",
    "\n",
    "RandomizedSearchCV will train many models (defined by n_iter_ and save each one as variables, the code below creates a variable for the best model and prints the hyperparameters. In this case, we haven’t passed a scoring system to the function, so it defaults to accuracy. This function also uses cross validation, which means it splits the data into five equal-sized groups and uses 4 to train and 1 to test the result. It will loop through each group and give an accuracy score, which is averaged to find the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "93ea2c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {'n_estimators': randint(50,500),\n",
    "              'max_depth': randint(1,20)}\n",
    "\n",
    "# Create an instance of the Random Forest model, with the default parameters\n",
    "rf = RandomForestClassifier(random_state=seed,\n",
    "                            oob_score=True)\n",
    "\n",
    "# Use random search to find the best hyperparameters\n",
    "rand_search = RandomizedSearchCV(rf, \n",
    "                                 param_distributions = param_dist, \n",
    "                                 n_iter=5, \n",
    "                                 cv=5,\n",
    "                                 random_state=seed)\n",
    "\n",
    "# Fit the random search object to our training data. We pass both the features and the target variable, so the model can learn.\n",
    "rand_search.fit(X_train, y_train)\n",
    "\n",
    "# Create a variable for the best model\n",
    "best_rf = rand_search.best_estimator_\n",
    "\n",
    "# Print the best hyperparameters\n",
    "#print('Best hyperparameters:', rand_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "121fe577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "OOB error: 0.0000\n"
     ]
    }
   ],
   "source": [
    "## At this point, we have a trained Random Forest model, but we need to find out whether it is making accurate predictions\n",
    "# Generate predictions with the best model\n",
    "y_pred = best_rf.predict(X_test)\n",
    "\n",
    "## Evaluate this model using accuracy, precision, and recall; we check the predictions against the actual values in the test set and count up how many the model got right\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "oob = 1 - best_rf.oob_score_\n",
    "#print(f'Accuracy: {accuracy}')\n",
    "#print(f'Precision: {precision}')\n",
    "#print(f'Recall: {recall}')\n",
    "#print(f'OOB error: {oob:.4f}')\n",
    "       \n",
    "## Get the importance of each feature, using the model’s internal score to find the best way to split the data within each decision tree\n",
    "# Create a series containing feature importances from the model and feature names from the training data\n",
    "feature_importances = pd.Series(best_rf.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
    "#feature_importances.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4b1d0ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## write output table\n",
    "res = {'autoencoder_parameters': [autoencoder_parameters],\n",
    "       'feature': [feature],\n",
    "       'test_size': [test_size],\n",
    "       'seed': [seed],\n",
    "       'accuracy': [accuracy],\n",
    "       'precision': [precision],\n",
    "       'recall': [recall],\n",
    "       'oob': [oob]}\n",
    "# append AE components (the number of them varies between runs)\n",
    "for i,feature_importance in enumerate(feature_importances.sort_index()):\n",
    "    res[f'ae{i+1}'] = feature_importance\n",
    "\n",
    "pd.DataFrame(res).to_csv(f'{autoencoder_parameters}_{feature}_{test_size}_{seed}_res.tsv', header=True, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7aff47",
   "metadata": {},
   "source": [
    "Visualize the first 3 trees\n",
    "---------------------------\n",
    "\n",
    "Each tree image is limited to only showing the first few nodes. These trees can get very large and difficult to visualize. The colors represent the majority class of each node (boxes). The colors get darker the closer the node gets to being fully a category. Each node also contains the following information:\n",
    "\n",
    "1- The variable name and value used for splitting\n",
    "\n",
    "2- The % of total samples in each split\n",
    "\n",
    "3- The % split between classes in each split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171e75cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for i in range(3):\n",
    "    tree = best_rf.estimators_[i]\n",
    "    dot_data = export_graphviz(tree,\n",
    "                               feature_names=X_train.columns,  \n",
    "                               filled=True,  \n",
    "                               max_depth=2, \n",
    "                               impurity=False, \n",
    "                               proportion=True)\n",
    "    graph = graphviz.Source(dot_data)\n",
    "    display(graph)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54780f0e",
   "metadata": {},
   "source": [
    "Confusion matrix\n",
    "----------------\n",
    "\n",
    "It plots what the model predicted against what the correct prediction was.\n",
    "We can use this to understand the tradeoff between false positives (top right) and false negatives (bottom left)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0b8528",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(y_test, y_pred), \n",
    "#                       display_labels=True).plot()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
